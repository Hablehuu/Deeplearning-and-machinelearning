{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'pic1.jpg'\n",
    "img_path2 = 'pic2.png'\n",
    "img_path3 = 'pic3.jpg'\n",
    "images = [img_path,img_path2,img_path3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "Predicted: [('n03720891', 'maraca', 0.70883465), ('n03627232', 'knot', 0.12974116), ('n06596364', 'comic_book', 0.09969014)]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Predicted: [('n09472597', 'volcano', 0.5052898), ('n09468604', 'valley', 0.24283153), ('n03891251', 'park_bench', 0.058718342)]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Predicted: [('n02124075', 'Egyptian_cat', 0.5128608), ('n02123045', 'tabby', 0.16944222), ('n04589890', 'window_screen', 0.14576758)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for image in images:\n",
    "    img = keras.utils.load_img(image, target_size=(224, 224))\n",
    "    x = keras.utils.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 192ms/step\n",
      "Predicted: [('n03720891', 'maraca', 0.7146983), ('n06596364', 'comic_book', 0.11047901), ('n03724870', 'mask', 0.043612972)]\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Predicted: [('n09468604', 'valley', 0.3789382), ('n09472597', 'volcano', 0.15442286), ('n09193705', 'alp', 0.039117113)]\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Predicted: [('n02124075', 'Egyptian_cat', 0.3933159), ('n02123045', 'tabby', 0.34667197), ('n02123159', 'tiger_cat', 0.1569642)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for image in images:\n",
    "    img = keras.utils.load_img(image, target_size=(224, 224))\n",
    "    x = keras.utils.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EfficientNetV2M\n",
    "from keras.applications.efficientnet import EfficientNetB7\n",
    "from keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB7(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "Predicted: [('n03888257', 'parachute', 0.32841113), ('n03627232', 'knot', 0.12577166), ('n02782093', 'balloon', 0.088213265)]\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "Predicted: [('n09468604', 'valley', 0.32421666), ('n02859443', 'boathouse', 0.16733956), ('n02793495', 'barn', 0.13650851)]\n",
      "1/1 [==============================] - 1s 534ms/step\n",
      "Predicted: [('n02123045', 'tabby', 0.5062912), ('n02123159', 'tiger_cat', 0.2739568), ('n02124075', 'Egyptian_cat', 0.076381475)]\n"
     ]
    }
   ],
   "source": [
    "for image in images:\n",
    "    img = keras.utils.load_img(image, target_size=(600, 600))\n",
    "    x = keras.utils.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "num_classes = 10\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:918: The name tf.data.get_output_shapes is deprecated. Please use tf.compat.v1.data.get_output_shapes instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:918: The name tf.data.get_output_shapes is deprecated. Please use tf.compat.v1.data.get_output_shapes instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
    "    'eurosat',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n"
     ]
    }
   ],
   "source": [
    "class_labels = metadata.features['label'].names\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "675/675 [==============================] - 88s 129ms/step - loss: 0.9772 - accuracy: 0.8311 - val_loss: 0.4467 - val_accuracy: 0.8674\n",
      "Epoch 2/10\n",
      "675/675 [==============================] - 84s 124ms/step - loss: 0.2779 - accuracy: 0.9119 - val_loss: 0.4297 - val_accuracy: 0.8819\n",
      "Epoch 3/10\n",
      "675/675 [==============================] - 84s 124ms/step - loss: 0.1841 - accuracy: 0.9406 - val_loss: 0.4423 - val_accuracy: 0.8859\n",
      "Epoch 4/10\n",
      "675/675 [==============================] - 82s 122ms/step - loss: 0.1623 - accuracy: 0.9456 - val_loss: 0.4492 - val_accuracy: 0.8930\n",
      "Epoch 5/10\n",
      "675/675 [==============================] - 82s 121ms/step - loss: 0.1479 - accuracy: 0.9512 - val_loss: 0.4820 - val_accuracy: 0.8848\n",
      "Epoch 6/10\n",
      "675/675 [==============================] - 81s 121ms/step - loss: 0.1545 - accuracy: 0.9516 - val_loss: 0.6084 - val_accuracy: 0.8830\n",
      "Epoch 7/10\n",
      "675/675 [==============================] - 86s 127ms/step - loss: 0.1236 - accuracy: 0.9600 - val_loss: 0.6586 - val_accuracy: 0.8752\n",
      "Epoch 8/10\n",
      "675/675 [==============================] - 90s 133ms/step - loss: 0.1276 - accuracy: 0.9621 - val_loss: 0.6577 - val_accuracy: 0.8848\n",
      "Epoch 9/10\n",
      "675/675 [==============================] - 91s 135ms/step - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.6640 - val_accuracy: 0.8878\n",
      "Epoch 10/10\n",
      "675/675 [==============================] - 90s 133ms/step - loss: 0.0928 - accuracy: 0.9725 - val_loss: 0.6762 - val_accuracy: 0.8937\n",
      "85/85 [==============================] - 10s 116ms/step - loss: 0.7056 - accuracy: 0.8993\n",
      "Test Accuracy: 0.8992592692375183\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#classification layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#transfer learning model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=epochs, batch_size=batch_size, validation_data=val_ds)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Fine-tuning (Optional)\n",
    "# Uncomment the following lines to unfreeze some or all of the pre-trained layers for fine-tuning\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(train_data, train_labels, epochs=num_epochs, batch_size=batch_size, validation_data=(val_data, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 6s 0us/step\n",
      "Epoch 1/4\n",
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 66s 95ms/step - loss: 0.4341 - accuracy: 0.8794 - val_loss: 0.2433 - val_accuracy: 0.9170\n",
      "Epoch 2/4\n",
      "675/675 [==============================] - 69s 103ms/step - loss: 0.1641 - accuracy: 0.9458 - val_loss: 0.2339 - val_accuracy: 0.9200\n",
      "Epoch 3/4\n",
      "675/675 [==============================] - 73s 109ms/step - loss: 0.1076 - accuracy: 0.9640 - val_loss: 0.2555 - val_accuracy: 0.9263\n",
      "Epoch 4/4\n",
      "675/675 [==============================] - 73s 109ms/step - loss: 0.0963 - accuracy: 0.9669 - val_loss: 0.3452 - val_accuracy: 0.9159\n",
      "85/85 [==============================] - 8s 91ms/step - loss: 0.3685 - accuracy: 0.9144\n",
      "Test Accuracy: 0.9144444465637207\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#classification layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#transfer learning model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=epochs, batch_size=batch_size, validation_data=val_ds)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      "258076736/258076736 [==============================] - 19s 0us/step\n",
      "Epoch 1/4\n",
      "675/675 [==============================] - 184s 253ms/step - loss: 1.3172 - accuracy: 0.5668 - val_loss: 0.7539 - val_accuracy: 0.7496\n",
      "Epoch 2/4\n",
      "675/675 [==============================] - 166s 245ms/step - loss: 0.7128 - accuracy: 0.7610 - val_loss: 0.7173 - val_accuracy: 0.7619\n",
      "Epoch 3/4\n",
      "675/675 [==============================] - 172s 254ms/step - loss: 0.6013 - accuracy: 0.7937 - val_loss: 0.6379 - val_accuracy: 0.7885\n",
      "Epoch 4/4\n",
      "675/675 [==============================] - 160s 237ms/step - loss: 0.5412 - accuracy: 0.8129 - val_loss: 0.5779 - val_accuracy: 0.8030\n",
      "85/85 [==============================] - 16s 190ms/step - loss: 0.5520 - accuracy: 0.8115\n",
      "Test Accuracy: 0.8114814758300781\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "\n",
    "\n",
    "base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#classification layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#transfer learning model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=epochs, batch_size=batch_size, validation_data=val_ds)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "675/675 [==============================] - 64s 92ms/step - loss: 0.4116 - accuracy: 0.8838 - val_loss: 0.2889 - val_accuracy: 0.9004\n",
      "Epoch 2/4\n",
      "675/675 [==============================] - 60s 89ms/step - loss: 0.1662 - accuracy: 0.9444 - val_loss: 0.2524 - val_accuracy: 0.9193\n",
      "Epoch 3/4\n",
      "675/675 [==============================] - 60s 89ms/step - loss: 0.0996 - accuracy: 0.9658 - val_loss: 0.2473 - val_accuracy: 0.9281\n",
      "Epoch 4/4\n",
      "675/675 [==============================] - 60s 89ms/step - loss: 0.0786 - accuracy: 0.9724 - val_loss: 0.3048 - val_accuracy: 0.9252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasui\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "num_classes = 10\n",
    "epochs = 4\n",
    "\n",
    "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
    "    'eurosat',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_labels = metadata.features['label'].names\n",
    "\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#classification layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#transfer learning model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "retrainedmodel = model.fit(train_ds, epochs=epochs, batch_size=batch_size, validation_data=val_ds)\n",
    "model.save(\"demo4model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
